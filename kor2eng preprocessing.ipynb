{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from dataset import get_vocab, index_sents\n",
    "from konlpy.tag import Twitter\n",
    "from hangul_romanize import Transliter\n",
    "from hangul_romanize.rule import academic\n",
    "from separator import Separator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get top n words from crawled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414455"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "with open('data/kwatchtower') as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        lines.append(line.strip('\\n'))\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines processed...\n",
      "50000 lines processed...\n",
      "100000 lines processed...\n",
      "150000 lines processed...\n",
      "200000 lines processed...\n",
      "250000 lines processed...\n",
      "300000 lines processed...\n",
      "350000 lines processed...\n",
      "400000 lines processed...\n",
      "CPU times: user 4min 14s, sys: 520 ms, total: 4min 15s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens = []\n",
    "for idx, line in enumerate(lines):\n",
    "    toks = twitter.pos(line, stem=False)\n",
    "    for tup in toks:\n",
    "        tok = tup[0]\n",
    "        if re.findall(r'[가-힣]+', tok) and 1 < len(tok) < 5:\n",
    "            tokens.append(tok)\n",
    "    if idx % 50000 == 0:\n",
    "        print(idx, \"lines processed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process data into sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3913912 41616\n"
     ]
    }
   ],
   "source": [
    "token_counts = Counter(tokens)\n",
    "x_words = [t[0] for t in token_counts.most_common(100000)]\n",
    "print(len(tokens), len(x_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transliterizer = Transliter(academic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 348 ms, sys: 4 ms, total: 352 ms\n",
      "Wall time: 352 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_words = [re.sub(r'[^a-z]', '', transliterizer.translit(w)) for w in x_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "습니다 \t seubnida\n",
      "사람 \t salam\n",
      "우리 \t uli\n",
      "니다 \t nida\n",
      "여호와 \t yeohowa\n",
      "에서 \t eseo\n",
      "하느님 \t haneunim\n",
      "으로 \t eulo\n",
      "입니 \t ibni\n",
      "에게 \t ege\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(x_words[i], '\\t', y_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㅅ', 'ㅡ', 'ㅂ', 'ㄴ', 'ㅣ', 'ㄷ', 'ㅏ']\n",
      "50\n",
      "CPU times: user 252 ms, sys: 4 ms, total: 256 ms\n",
      "Wall time: 255 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_data = [Separator(w).sep_all for w in x_words]\n",
    "print(x_data[0])\n",
    "x_vocab = list(set(w for l in x_data for w in l))\n",
    "print(len(x_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s', 'e', 'u', 'b', 'n', 'i', 'd', 'a']\n",
      "20\n",
      "CPU times: user 24 ms, sys: 4 ms, total: 28 ms\n",
      "Wall time: 27.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_data = [list(w) for w in y_words]\n",
    "print(y_data[0])\n",
    "y_vocab = list(set(w for l in y_data for w in l))\n",
    "print(len(y_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total vocab size: 50 \n",
      "\n",
      "\n",
      "trunc vocab size: 50 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "kor2idx, idx2kor = get_vocab(x_data, len(x_vocab)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total vocab size: 20 \n",
      "\n",
      "\n",
      "trunc vocab size: 20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "eng2idx, idx2eng = get_vocab(y_data, len(y_vocab)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 192 ms, sys: 0 ns, total: 192 ms\n",
      "Wall time: 192 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_text_idx = index_sents(x_data, kor2idx)\n",
    "y_text_idx = index_sents(y_data, eng2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41616, 41616)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_text_idx), len(y_text_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train-test split and save to numpy binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = [i for i in range(len(x_text_idx))]\n",
    "train_idx, test_idx, y_train, y_test = train_test_split(indices, y_text_idx, test_size=0.1)\n",
    "\n",
    "def get_sublist(lst, indices):\n",
    "    result = []\n",
    "    for idx in indices:\n",
    "        result.append(lst[idx])\n",
    "    return result\n",
    "\n",
    "x_train = get_sublist(x_text_idx, train_idx)\n",
    "x_test = get_sublist(x_text_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37454, 4162, 37454, 4162)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numpy_save(saves, names):\n",
    "    for idx, item in enumerate(saves):\n",
    "        np.save('encoded/{0}.npy'.format(names[idx]), item)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saves = [\n",
    "x_words, y_words,\n",
    "x_vocab, y_vocab,\n",
    "kor2idx, idx2kor,\n",
    "eng2idx, idx2eng,\n",
    "train_idx, test_idx,\n",
    "x_train, x_test,\n",
    "y_train, y_test,\n",
    "]\n",
    "\n",
    "names = [\n",
    "'x_words', 'y_words',\n",
    "'x_vocab', 'y_vocab',\n",
    "'kor2idx', 'idx2kor',\n",
    "'eng2idx', 'idx2eng',\n",
    "'train_idx', 'test_idx',\n",
    "'x_train', 'x_test',\n",
    "'y_train', 'y_test',\n",
    "]\n",
    "\n",
    "numpy_save(saves, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 22\n"
     ]
    }
   ],
   "source": [
    "x_len = [len(x) for x in x_data]\n",
    "y_len = [len(y) for y in y_data]\n",
    "print(max(x_len), max(y_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core_kor",
   "language": "python",
   "name": "core_kor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
